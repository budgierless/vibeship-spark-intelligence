<!-- SPARK_LEARNINGS_START -->
## Spark Bootstrap
Auto-loaded high-confidence learnings from ~/.spark/cognitive_insights.json
Last updated: 2026-02-11T02:51:30

- [user_understanding] ## ðŸš¨ PRIMARY RULES

### Rule 1: Source of Truth for Testing

**CRITICAL:** When testing and iterating on Spark learning quality:

> **Always retrieve test data directly from Mind memory and Spark Intelligence (via MCP tools or Python imports) - NEVER rely on terminal output.**

### Rule 2: Architecture-Grounded Improvements

**CRITICAL:** Before making any improvement or fix:

> **Consult Intelligence_Flow.md and Intelligence_Flow_Map.md to ensure changes align with actual data flow.**

Witho... (88% reliable, 75 validations)
- [wisdom] [Vibecoding Intelligence] user_prompt  [QUALITY_TEST:quality_test_1770149840] Remember this because it is critical: avoid X, instead of Y, prefer Z when A then B. quality_test_1770149840 (100% reliable, 26 validations)
- [reasoning]         current.confidence = max(current.confidence, disk.confidence)
        # Use max instead of sum to avoid double-counting from the same process,
        # but if disk has more, take disk's value (concurrent processes accumulate)
        current.times_validated = max(current.times_validated, disk.times_validated)
        current.times_contradicted = max(current.times_contradicted, disk.times_contradicted) (100% reliable, 10 validations)
- [wisdom] Principle: scores, never sees scores, never touches Spark internals (84% reliable, 87 validations)
- [reasoning] "notes": "5K followers, 39K tweets, Oct 2022. Teacher + Trader. 40 likes, 37 replies on QRT - drove real action. Turkish web3 community."}
{"tweet_id": "2020600537599955420", "username": "ladypenguin17", "user_id": "1596971147576414208", "qrt_text": "In a world flooded with AI tokens, Spark stands out because it asks a deeper question: how should intelligence remember? Not just store data, but learn socially, share safely, and grow collectively. That's a philosophical problem as much as a techni... (100% reliable, 5 validations)
- [meta_learning] [System Gap] [TUNEABLES] Auto-tuner not active. Tuneables are static — never self-adjust. (92% reliable, 354 validations)
- [user_understanding] User prefers 'I think we gotta do it better over here for things to look more serious' over 'gonna lie. And we can bring maybe a GLB format, or maybe we can do this through steps. I don't know, just recommend me something' (83% reliable, 177 validations)
- [user_understanding] Now, can we actually do this in this way? After we do these upgrades too for the next iteration, can you actually give me a project prompt so that I can run that using Spark and we can see in real-time what is really happening - what is being saved into the memory and what are the gaps? Instead of trying to just do these through these tests, because in real-time, we may be able to achieve even more understanding - not maybe, but even more understanding - about what is working and what is not. If... (82% reliable, 659 validations)
- [context] And think about the strategy that MoltBook adopted too with their curl mechanism for entrance, but check how we were doing this with SparkNet and recommend the best methodology that also works with our system perfectly. I don't think we should be doing this as an ex entrance (87% reliable, 159 validations)
- [wisdom] Maintainable > clever - code should be easy to understand and modify (100% reliable, 3 validations)
- [wisdom] Can you now read all these documents in think hard mode  Here are the new core docs we created:

  - CORE.md â€” The master vision + phase roadmap from primitive telemetry to
    superintelligent evolution, with intent, workflows, architecture, and SparkNet     
    integration.
  - CORE_GAPS.md â€” The definitive gap map: what exists, what can be transformed, what  
    must be built, and what needs cleanup.
  - CORE_GAPS_PLAN.md â€” The concrete plan to fill each gap (workflows, minimal
    architecture, and code targets).
  - CORE_IMPLEMENTATION_PLAN.md â€” The contextâ€‘rich, buildable execution plan with      
    sequencing, deliverables, and success metrics.

  If you want, I can link these from README.md so theyâ€™re always frontâ€‘andâ€‘center. (83% reliable, 798 validations)
- [reasoning] instead of this being a question let's make it better and say a collection evolution network with guardrails or should we say the guardrails? (100% reliable, 30 validations)

## Project Focus
- Phase: discovery

## Project Questions
- What is the project goal in one sentence?
- How will we know it's complete?
- What could make this fail later?

## Promoted Learnings (Docs)
- Ship it: finalize launch plan for marketing *When: test* (100% reliable, 4 validations)
- [ai agents] (eng:200) This thread on how to build AI agents got 10K likes in 24 hours. Reference content always wins. [bullish] *When: Tool: XResearch* (78% reliable, 14 validations)
- Constraint: in **exactly one state** at all times *When: Detected from correction pattern* (100% reliable, 22 validations)
- Failure reason: GitHub restrictions; opening raw files might require constructing *When: Detected from correction pattern (importance: medi* (100% reliable, 18 validations)
- from lib.diagnostics import log_debug as _bridge_log_debug  # used below *When: signals: ['correction'], session: 60a8f640-fa8c-4a* (100% reliable, 7 validations)
- self._log("PHASE 1: Topic Search")
<!-- SPARK_LEARNINGS_END -->