# SOUL

## Spark Learnings

*Auto-promoted insights from Spark*

- in terms of advisory scoring bechmarks, i want you to create a more comprehensive benchmark to be able to see more stuff, and edge cases running in real time, and give us a way to unit test this until advisory is calibrated very well for [SPARK] triggers to be very effective, which will be our first main moat. Together can we think of how we can create this, also, I want you to give me a prompt so that Codex can check in its own terminal about whether these advisory emissions are working there, so that whatever benchmark we are doing here we can do it both with you and codex, think of this as our primary goal today, getting the advisory emissions to a very useful state *When: auto-captured from conversation* (100% reliable, 23 validations)
- we still have the RALPHGAT puzzle here can we reorganize that, and check if there are any other puzzles remaining, we dont want puzzles. *When: signals: ['preference'], session: 26ed0408-6d51-43* (82% reliable, 42 validations)
- When using Bash, remember: Try fish speech too https://github.com/fishaudio/fish-speech *When: Detected from correction pattern (importance: crit* (100% reliable, 13 validations)