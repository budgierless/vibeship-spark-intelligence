<!-- SPARK_LEARNINGS_START -->
## Spark Bootstrap
Auto-loaded high-confidence learnings from ~/.spark/cognitive_insights.json
Last updated: 2026-02-04T17:19:15

- [user_understanding] ## ðŸš¨ PRIMARY RULES

### Rule 1: Source of Truth for Testing

**CRITICAL:** When testing and iterating on Spark learning quality:

> **Always retrieve test data directly from Mind memory and Spark Intelligence (via MCP tools or Python imports) - NEVER rely on terminal output.**

### Rule 2: Architecture-Grounded Improvements

**CRITICAL:** Before making any improvement or fix:

> **Consult Intelligence_Flow.md and Intelligence_Flow_Map.md to ensure changes align with actual data flow.**

Witho... (100% reliable, 4 validations)
- [self_awareness] I struggle with Bash fails with windows_path -> Fix: Use forward slashes (/) instead of backslas tasks (27% reliable, 1364 validations)
- [self_awareness] I struggle with Bash fails with file_not_found -> Fix: Verify path exists with Read or ls first tasks (26% reliable, 2251 validations)
- [self_awareness] I struggle with Bash fails with syntax_error -> Fix: Check syntax, look for missing quotes or br tasks (24% reliable, 1190 validations)
- [self_awareness] I struggle with Bash fails with command_not_found -> Fix: Check command spelling or install requ tasks (12% reliable, 500 validations)
- [self_awareness] I struggle with Bash fails with windows_encoding -> Fix: Use ASCII characters or set UTF-8 encod tasks (11% reliable, 431 validations)
- [self_awareness] I struggle with Bash fails with connection_error -> Fix: Check if service is running on expected tasks (10% reliable, 426 validations)
- [self_awareness] I struggle with Bash fails with permission_denied -> Fix: Check file permissions or run with ele tasks (10% reliable, 325 validations)
- [self_awareness] I struggle with Bash fails with json_error -> Fix: Verify JSON format is valid (recovered 100%) tasks (10% reliable, 339 validations)
- [self_awareness] I struggle with Bash fails with timeout -> Fix: Reduce scope or increase timeout tasks (24% reliable, 1321 validations)
- [user_understanding] Now, can we actually do this in this way? After we do these upgrades too for the next iteration, can you actually give me a project prompt so that I can run that using Spark and we can see in real-time what is really happening - what is being saved into the memory and what are the gaps? Instead of trying to just do these through these tests, because in real-time, we may be able to achieve even more understanding - not maybe, but even more understanding - about what is working and what is not. If... (99% reliable, 103 validations)
- [user_understanding] User prefers 'I think we gotta do it better over here for things to look more serious' over 'gonna lie. And we can bring maybe a GLB format, or maybe we can do this through steps. I don't know, just recommend me something' (76% reliable, 112 validations)

## Project Focus
- Phase: discovery

## Project Questions
- What is the project goal in one sentence?
- How will we know it's complete?
- What could make this fail later?

## Promoted Learnings (Docs)
- User learns by building - figure it out as they go, hands-on *When: Learning style* (100% reliable, 3 validations)
- User prefers Just try it, user will correct if wrong for assumptions *When: When assumptions is relevant* (73% reliable, 8 validations)
- User prefers Try different angles - brute force approaches for unstuck_method *When: When unstuck_method is relevant* (100% reliable, 7 validations)
- User prefers Build something - learn by doing for learning_style *When: When learning_style is relevant* (86% reliable, 6 validations)
- User aversion: when we are using rounded corners for components *When: Chat message: I hate when we are using rounded cor* (100% reliable, 15 validations)
- User wanted: no, I meant...")
<!-- SPARK_LEARNINGS_END -->