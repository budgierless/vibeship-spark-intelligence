# Prompt Run: #10 Weekly Review, #2 Memory Retrieval Audit, #6 Tuneables Experiment Plan

Generated: 2026-02-15

This is a single running log for using the prompt library:
- `prompts/SPARK_INTELLIGENCE_PROMPT_LIBRARY.md`

Sources used (evidence):
- `docs/reports/2026-02-15_124723_advisory_self_review.md`
- `docs/reports/2026-02-14_retrieval_routing_abcd_live_v1.md`
- `docs/reports/2026-02-13_advisory_repeat_abcd_controlled_delta_v1.md`
- `docs/memory-retrieval-status.md`
- `%USERPROFILE%\\.spark\\tuneables.json`
- `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`
- `%USERPROFILE%\\.spark\\advisory_engine.jsonl`
- `%USERPROFILE%\\.spark\\advisory_emit.jsonl`
- `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl`
- `%USERPROFILE%\\.spark\\sync_stats.json`
- `%USERPROFILE%\\.spark\\pipeline_state.json`

---

## Prompt #10: "Compound the Learnings" Weekly Review

Window (chosen): 2026-02-09 to 2026-02-15 (inclusive)

### What Improved (Evidence-Backed)
- Retrieval routing A/B/C/D executed and a winner was chosen, with Arm C (`lexical_weight=0.28`) applied live to `~/.spark/tuneables.json -> retrieval.overrides.*`. Evidence: `docs/reports/2026-02-14_retrieval_routing_abcd_live_v1.md`, `%USERPROFILE%\\.spark\\tuneables.json`.
- Advisory repeat A/B/C/D suggests repeat-noise can be reduced: `feedback_top_share` is 57.14% in A/B, 36.36% in C, 25.00% in D. Evidence: `docs/reports/2026-02-13_advisory_repeat_abcd_controlled_delta_v1.md`.
- Memory retrieval has a concrete quality/latency benchmark surface and explicit diagnostics + error taxonomy contract. Evidence: `docs/memory-retrieval-status.md`.

### What Regressed (Evidence-Backed)
- Advisory self-review (12h window) shows advisory trace coverage at 0/11 (0%), and engine trace coverage at 3/13 (23.08%), which blocks attribution. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
- Advisory noise is highly concentrated in that same 12h window: "Top repeated advisories account for ~92.0% of all advice items". Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
- Current pipeline telemetry shows consecutive empty cycles (12) which may be normal if idle, but indicates the learning pipeline is not processing any queued events right now. Evidence: `%USERPROFILE%\\.spark\\pipeline_state.json`, `%USERPROFILE%\\.spark\\pipeline_metrics.json`.

### Top Learnings To Keep (Evidence-Backed)
- Constraint: in exactly one state at all times. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.
- Always read a file before Edit to verify current content. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.
- Error taxonomy split (`auth|timeout|policy|transport|unknown`) for retrieval failures (prevents false "auth blocked" narratives). Evidence: `docs/memory-retrieval-status.md`.

### Top Learnings To Kill/Suppress (Evidence-Backed)
- Suppress long repeated "When using Bash..." advisory family (high repetition in window, low actionability for PowerShell-first operation). Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
- Suppress long repeated "lets push gitthub..." advisory family (high repetition, not tied to current acceptance). Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl` (recent window counts below).

### Next Week: 3 Bets (Measurable + Rollback)
1. Improve advisory trace discipline end-to-end. Metric: advisory trace coverage from 0% toward >=60%. Rollback: revert strict trace requirements if strict effectiveness drops. Evidence baseline: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
2. Reduce repeat-noise concentration. Metric: top-repeat share from ~92% toward <=40%. Rollback: if critical misses increase. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `docs/reports/2026-02-13_advisory_repeat_abcd_controlled_delta_v1.md`.
3. Ship retrieval diagnostics + error-kind classification coverage. Metric: 100% non-empty `error_kind` for failures. Rollback: disable new diagnostics endpoints if destabilizing. Evidence: `docs/memory-retrieval-status.md`.

---

## Prompt #2: Memory Retrieval Audit (Wins/Misses With Evidence)

Window (available evidence): 2026-02-15 14:26:43Z to 2026-02-15 18:24:29Z for retrieval routing (`~/.spark/advisor/retrieval_router.jsonl`).

### Evidence Summary
- Routing events analyzed: 834. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Advisory engine event slice available: 2026-02-15 18:20:03Z to 2026-02-15 18:24:58Z (500 events). Evidence: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.
- Advisory emit history available: 2026-02-13 23:05:31Z to 2026-02-15 18:24:38Z (500 emits). Evidence: `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.
- Sync status: multiple optional adapters are disabled (CLAUDE.md, Cursor, Windsurf, Clawdbot); core adapters `exports` and `openclaw` report success. Evidence: `%USERPROFILE%\\.spark\\sync_stats.json`.

### Retrieval Wins
- Some calls do retrieve non-empty semantic results under the `balanced_spend` profile (10 events) with non-zero `primary_count` (4-5) and non-zero `primary_top_score` (~0.19-0.24). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` (profile_name=`balanced_spend` rows).

### Retrieval Misses / Failure Modes
- The retrieval router is overwhelmingly in `local_free` profile: 824/834 events (98.8%). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Route outcomes are dominated by `empty`: 711/834 (85.3%). Escalation happens 85/834 (10.2%). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Primary retrieval quality is very low: only 40/834 events have `primary_count > 0` (4.8%), and 0/834 have `primary_top_score > 0.5`. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Top miss reasons are consistently logged:
  - `empty_primary`: 794
  - `agentic_rate_cap`: 739
  - `weak_primary_score`: 534
  - `weak_primary_count`: 525
  Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- The tuned routing overrides (Arm C values) are not being applied to most traffic because `local_free` events that include routing parameters show baseline-like values (0.25/0.15/0.03/0.90/0.1) while `balanced_spend` events show the tuned values (0.28/0.18/0.05/0.92/0.2). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`, `%USERPROFILE%\\.spark\\tuneables.json`, `docs/reports/2026-02-14_retrieval_routing_abcd_live_v1.md`.

### Advisory Delivery Misses (Policy Suppression)
- In the `advisory_engine.jsonl` slice, `no_emit` happens 200/500 times, and all 200 are `error_kind=policy` with `error_code=AE_GATE_SUPPRESSED`. Evidence: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.
- This indicates advice candidates exist but are being blocked at the gate for this window; if this is intended, it should be reflected in trace-linked success criteria, otherwise it hides issues behind "no advice". Evidence: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`, `docs/reports/2026-02-15_124723_advisory_self_review.md`.

### Noise Snapshot (Recent 72h, Feedback Requests)
- Recent (last ~72h) feedback requests show high repetition of a small set of advice:
  - "Constraint: in **exactly one state** at all times" (187)
  - "Always Read a file before Edit to verify current content" (93)
  - "[Caution] I struggle with WebFetch fails with other tasks" (78)
  Evidence: `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl` (filtered by `created_at`).

### Tuning Actions (Ordered, No New Features)
1. Fix profile selection so the tuned `retrieval.overrides.*` are applied to the majority of tool calls (or ensure `local_free` also honors the overrides). Success metric: `route=empty` share drops materially and `primary_count>0` increases. Evidence motivating: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
2. Reduce the dominance of `agentic_rate_cap` when `empty_primary` is true (either by raising `agentic_rate_limit` for `local_free`, or by allowing escalation on repeated empties). Success metric: fewer `agentic_rate_cap` blocks and higher `returned_count` on escalations. Evidence motivating: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
3. Reconcile advisory gate suppression with desired behavior: if `AE_GATE_SUPPRESSED` blocks 200/250 decision points, the system needs an explicit target for that ratio. Success metric: lower policy-suppressed share or clearer trace-linked justification. Evidence motivating: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.

---

## Prompt #6: Tuneables Experiment Plan (A/B/C/D With Rollback)

### Proposed Change (High-Leverage)
Make retrieval policy consistent and more permissive so primary retrieval is non-empty more often (reducing `route=empty` and `empty_primary` dominance), while controlling cost/latency and repeat noise.

Why this is the candidate:
- In the analyzed routing window, `route=empty` is 711/834 (85.3%) and `empty_primary` is logged 794 times. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- `agentic_rate_cap` is logged 739 times, meaning even when escalation is indicated, it is frequently blocked. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Semantic retrieval frequently yields no final results even when embeddings are available (1501/2246 empty final_results). Evidence: `%USERPROFILE%\\.spark\\logs\\semantic_retrieval.jsonl`.

### Experiment Design

Variants (A/B/C/D):
1. **A (Baseline)**: current runtime behavior (no changes).
2. **B (Consistency)**: ensure all Spark processes load the same retrieval policy:
   - Set/confirm `retrieval.level="2"` in `%USERPROFILE%\\.spark\\tuneables.json`.
   - Restart Spark services that host the advisor/advisory engine so `SparkAdvisor.retrieval_policy` reloads (it is loaded at initialization). Evidence: `lib/advisor.py` (loads policy in `SparkAdvisor.__init__`).
3. **C (Permissive Primary)**: B + relax matching thresholds used by the advisor filter to reduce empty finals:
   - `retrieval.overrides.semantic_context_min`: 0.18 -> 0.12
   - `retrieval.overrides.semantic_lexical_min`: 0.05 -> 0.02
4. **D (Reduce Rate-Cap Blocking)**: C + raise escalation allowance:
   - `retrieval.overrides.agentic_rate_limit`: 0.20 -> 0.35
   - keep `retrieval.overrides.agentic_rate_window` at 80 (unchanged)

Primary metrics:
- Retrieval router:
  - `route=empty` share
  - `primary_count>0` rate
  - `agentic_rate_cap` frequency
  - `returned_count` mean/p95 (for `semantic|semantic-agentic`)
  Evidence source: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Semantic retrieval:
  - `final_results_empty` rate
  Evidence source: `%USERPROFILE%\\.spark\\logs\\semantic_retrieval.jsonl`.
- Advisory delivery:
  - `AE_GATE_SUPPRESSED` share (no-emit reason histogram)
  Evidence source: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.
- Repeat-noise:
  - top 1 and top 3 advice share
  Evidence source: `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl`, `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.

Secondary metrics:
- Latency: `route_elapsed_ms` (router) and `elapsed_ms` (advisory engine) p95.
- Safety: `critical_miss_rate`/realism objective if you run contract benches. Evidence surface: `docs/ADVISORY_BENCHMARK_SYSTEM.md`.

Sample size / timebox:
- Minimum: 10 minutes per variant under real work, or run a standardized synthetic workload.
- Recommended synthetic runner: `python scripts/advisory_controlled_delta.py --rounds 160 --force-live --out docs/reports/<variant>_controlled_delta.json`
  - Note: by default this script resets `~/.spark/advice_feedback_state.json`; pass `--no-reset-feedback-state` if you want to preserve it.

Stop conditions:
- If p95 advisory latency exceeds 3500ms (current `advisory_engine.max_ms`) or spikes materially.
- If repeat-noise worsens (top-1 share rises) without a matching lift in retrieval non-empties.
- If `semantic_retrieval.jsonl` starts showing increased `final_results` but advice quality regresses (more irrelevant emits).

Rollback criteria:
- If `route=empty` does not improve by at least 20% relative (e.g., 85% -> <=68%) after C or D.
- If repeat-noise gets worse (top-3 share increases) without higher strict effectiveness.
- If engine suppression dominates more than baseline (higher `AE_GATE_SUPPRESSED` share) and trace coverage remains low.

Rollback mechanism:
- Restore `%USERPROFILE%\\.spark\\tuneables.json` from a known-good backup (example present: `%USERPROFILE%\\.spark\\tuneables.json.prune_advisor_retrieval_policy_backup_20260214_034633`) or revert the specific keys.
- Restart services to apply rollback (policy is loaded at advisor init).

### Execution Steps (Minimal)
1. Snapshot current tuneables + logs:
   - Copy `%USERPROFILE%\\.spark\\tuneables.json` to a timestamped backup.
   - Record baseline router stats from `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
2. Apply Variant B (consistency) and restart Spark services.
3. Run the same workload for each variant (real work window or `scripts/advisory_controlled_delta.py`) and record:
   - router stats
   - semantic final_results_empty rate
   - advisory no-emit histogram (error_code)
4. Choose winner using primary metrics; only keep the smallest change-set that achieves the lift.

### Variant B (Executed) Findings (2026-02-15)

Artifacts created:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantB_20260215_234717.bak`
- Controlled delta (pre): `docs/reports/2026-02-15_233443_variantB_pre.json`
- Controlled delta (post, before BOM fix): `docs/reports/2026-02-15_233443_variantB_post.json`
- Controlled delta (post, after BOM fix): `docs/reports/2026-02-15_233443_variantB_post_bomfix.json`

Root cause discovered (blocking all tuneables usage):
- `%USERPROFILE%\\.spark\\tuneables.json` contained a UTF-8 BOM.
- Multiple loaders use `json.loads(tuneables.read_text(encoding="utf-8"))`; Python raises `JSONDecodeError: Unexpected UTF-8 BOM`.
- The advisor retrieval policy loader silently swallowed the exception and fell back to defaults (Level 1 / `local_free`), explaining why routing overrides were not applied.

Fix applied:
- Rewrote `%USERPROFILE%\\.spark\\tuneables.json` by reading with `utf-8-sig` and writing without BOM (UTF-8).
- Restarted Spark services (`python -m spark.cli down` then `python -m spark.cli up`) so long-lived processes reload tuneables.
- Hardened runtime loaders to accept UTF-8 with BOM by switching tuneables reads to `encoding="utf-8-sig"` (prevents recurrence even if an editor writes BOM).

Measured effect (same synthetic workload: `scripts/advisory_controlled_delta.py --rounds 120 --force-live --no-reset-feedback-state`):
- **Pre (2026-02-15 19:47:31Z)** router window (120 rows):
  - Profile: 120/120 `local_free` (level 1)
  - Routes: `empty` 105, `semantic-agentic` 12, `semantic` 3
  - `escalated_true`: 12/120
- **Post after BOM fix (2026-02-15 19:57:01Z)** router window (120 rows):
  - Profile: 120/120 `balanced_spend` (level 2)
  - Routes: `empty` 92, `semantic-agentic` 24, `semantic` 4
  - `escalated_true`: 24/120
- Advisory engine p95 latency increased (expected with more escalation): p95 ~420ms (pre) -> ~540ms (post after BOM fix). Evidence: JSON artifacts above.

### Variant C (Executed) Findings (2026-02-15)

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.semantic_context_min`: 0.18 -> 0.12
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.semantic_lexical_min`: 0.05 -> 0.02

Artifacts:
- Controlled delta: `docs/reports/2026-02-15_233443_variantC.json`

Measured effect vs Variant B (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows):
  - **B** routes: `empty` 92, `semantic-agentic` 24, `semantic` 4 (empty share 76.7%)
  - **C** routes: `semantic` 120, `empty` 0 (empty share 0.0%)
  - **B** `primary_count>0`: 4/120
  - **C** `primary_count>0`: 120/120
- Router detail in C:
  - `returned_count` mean: 1.925 (min 1, max 4)
  - `primary_top_score` mean: 0.0139 (min 0.0, max 0.0617)  (note: still extremely low)
- Advisory engine p95 latency:
  - **B** p95 ~540ms
  - **C** p95 ~759ms

Decision:
- Keep Variant C changes (massive reduction in `route=empty`, within advisory time budgets).

### Variant C+ (Executed) Findings (2026-02-15)

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.escalate_on_weak_primary`: false -> true

Artifacts:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantCplus_20260216_005907.bak`
- Controlled delta: `docs/reports/2026-02-16_010226_variantC_plus.json`

Measured effect vs Variant C (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows; first 120 rows in `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` with `ts >= 2026-02-15T21:02:27Z`):
  - Routes: `semantic` 95, `semantic-agentic` 25, `empty` 0
  - `escalated_true`: 25/120
  - `primary_count>0`: 120/120
  - `returned_count` mean: 2.108 (min 1, max 7)
  - `primary_top_score` mean: 0.0144 (min 0.0, max 0.0680)  (note: still extremely low)
  - Top reasons: `weak_primary_score` 120, `agentic_rate_cap` 95
- Advisory engine p95 latency (from controlled delta JSON): p95 741.4ms (n=8 emitted)

Interpretation:
- `escalate_on_weak_primary=true` is taking effect (25/120 routes went `semantic-agentic`), but `agentic_rate_cap` is now the dominant limiter (95/120 rows log it).

### Variant D (Executed) Findings (2026-02-15)

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.agentic_rate_limit`: 0.2 -> 0.35

Artifacts:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantD_20260216_015256.bak`
- Controlled delta: `docs/reports/2026-02-16_015504_variantD_agentic_rate_035.json`

Measured effect vs Variant C+ (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows; first 120 rows in `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` with `ts >= 2026-02-15T21:55:05Z`):
  - Routes: `semantic` 78, `semantic-agentic` 42, `empty` 0
  - `escalated_true`: 42/120
  - `primary_count>0`: 120/120
  - `returned_count` mean: 2.733 (min 1, max 6)
  - `primary_top_score` mean: 0.0139 (min 0.0, max 0.0617)  (note: still extremely low)
  - Top reasons: `weak_primary_score` 120, `agentic_rate_cap` 78
- Advisory engine p95 latency (from controlled delta JSON): p95 389.2ms (n=7 emitted)

Decision:
- Keep `agentic_rate_limit=0.35` (material reduction in `agentic_rate_cap` frequency and higher `returned_count`), while tracking advisory emit rate and any quality regressions.

### Variant E (Executed) Findings (2026-02-15)

Goal:
- Reduce unnecessary `weak_primary_score` triggers by calibrating the score threshold to the observed score scale (scores peak around ~0.06 in this environment).

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.min_top_score_no_escalation`: 0.72 -> 0.02

Artifacts:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantE_20260216_024440.bak`
- Controlled delta: `docs/reports/2026-02-16_024647_variantE_minTopScore_002.json`

Measured effect vs Variant D (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows; first 120 rows in `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` with `ts >= 2026-02-15T22:46:47Z`):
  - Routes: `semantic` 80, `semantic-agentic` 40, `empty` 0
  - `escalated_true`: 40/120
  - `primary_count>0`: 120/120
  - `returned_count` mean: 2.783 (min 1, max 7)
  - `primary_top_score` mean: 0.01387 (min 0.0, max 0.0617)
  - Top reasons: `weak_primary_score` 82 (down from 120), `agentic_rate_cap` 42 (down from 78)
- Advisory engine p95 latency (from controlled delta JSON): p95 269.9ms (n=2 emitted)

Decision:
- Keep `min_top_score_no_escalation=0.02` for now (large drop in `weak_primary_score` and `agentic_rate_cap`), but the controlled-delta run emitted very little advice (2 emits) so this needs a longer soak window to be confident.

### Variant E Soak (Executed) Findings (2026-02-15)

Artifacts:
- Controlled delta: `docs/reports/2026-02-16_024920_variantE_soak_500.json`

Notes:
- This run recorded 250/500 rounds as `engine.routes.live` (not 500). It also recorded 0 emits (all latency percentiles are 0). This suggests the delta harness is not fully exercising the emit path under current gating/dedupe behavior for this longer run.

Router window (250 rows; first 250 rows in `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` with `ts >= 2026-02-15T22:49:20Z`):
- Routes: `semantic` 164, `semantic-agentic` 86, `empty` 0
- `escalated_true`: 86/250
- `primary_count>0`: 250/250
- `returned_count` mean: 2.888 (min 1, max 7)
- `primary_top_score` mean: 0.01147 (min 0.0, max 0.0617)
- Top reasons: `weak_primary_score` 185, `agentic_rate_cap` 99

---

## Post-Variant E Snapshot (2026-02-16)

Live retrieval routing since Variant E start (`ts >= 2026-02-15T22:46:47Z`):
- Routing events: 621. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Profile: 621/621 `balanced_spend` (level 2).
- Routes: `semantic` 407, `semantic-agentic` 214, `empty` 0.
- `primary_count>0`: 621/621.
- `returned_count` mean: 2.884 (p50 3, max 7).
- `primary_top_score` mean: 0.01083 (p50 0.0, max 0.0806).
- Top reasons: `weak_primary_score` 469, `agentic_rate_cap` 255.

## Controlled Delta Harness Update (2026-02-16)

Problem observed:
- Synthetic delta runs were heavily impacted by global dedupe suppression and had low/unstable emit counts, making advisory-engine KPIs hard to interpret.

Fixes applied (tooling only; no tuneables):
- `scripts/advisory_controlled_delta.py` now supports:
  - `--prompt-mode {constant,vary}`
  - `--tool-input-mode {synthetic,repo}`
  - records `end_ts` and includes `modes` in output JSON
- Default `session_prefix` is now `advisory-bench-*` (bench sessions bypass global/low-auth dedupe guards so emission metrics are measurable).

Validation artifact:
- Bench run (120 rounds): `docs/reports/2026-02-16_031645_harness_bench_repo_vary_120.json`
  - Engine events: `emitted` 7, `no_advice` 58, `no_emit` 55 (no global dedupe suppression).

## Autonomous Run-Improve Loop (2026-02-16)

Goal:
- Execute a full `run -> improve -> run -> improve -> run` loop autonomously and apply the best selective-AI policy under measured guardrails.

### Step 1: Instrumentation Upgrade

Changes:
- `lib/advisory_engine.py`:
  - implemented selective-AI mixed policy controls from tuneables:
    - `selective_ai_synth_enabled`
    - `selective_ai_min_remaining_ms`
    - `selective_ai_min_authority`
  - added suppression telemetry on no-emit rows:
    - `gate_reason`
    - `suppressed_count`
    - `suppressed_reasons`
  - added synthesis telemetry:
    - `synth_policy` (`packet_cached`, `programmatic_forced`, `selective_ai_auto`, `auto`, `programmatic_budget_fallback`)
- `scripts/advisory_controlled_delta.py`:
  - now reports `engine.error_codes`, `engine.synth_policy_counts`, and `engine.emitted_synth_policy_counts`.
  - added `--session-prefix` and `--trace-prefix` overrides for controlled routing.

Validation:
- `python -m pytest -q tests/test_advisory_dual_path_router.py tests/test_advisory_gate_suppression.py tests/test_advisor_tool_specific_matching.py` -> `20 passed`.
- `python -m pytest -q tests/test_advisory_preferences.py tests/test_cli_advisory.py` -> `17 passed`.

### Step 2: 3-Pass Selective-AI Tune Loop

Runner:
- `python scripts/run_advisory_selective_ai_tune_loop.py --rounds 120`

Artifacts:
- Pass 1: `docs/reports/20260216_144611_pass1_warning_1800_selective_loop.json`
- Pass 2: `docs/reports/20260216_144733_pass2_note_1800_selective_loop.json`
- Pass 3: `docs/reports/20260216_144853_pass3_note_2400_selective_loop.json`
- Loop result: `docs/reports/20260216_145005_selective_ai_tune_loop_result.json`
- Loop report: `docs/reports/20260216_145005_selective_ai_tune_loop_report.md`

Pass summary:
- `pass1_warning_1800`:
  - emitted `4`, no_emit `103`, no_advice `13`
  - p50 `310.3ms`, p95 `590.5ms`
  - emitted synth policy: `programmatic_forced=4`, `selective_ai_auto=0`
  - score `-227.5` (winner)
- `pass2_note_1800`:
  - emitted `1`, no_emit `106`, no_advice `13`
  - p50/p95 `591.1ms`
  - emitted synth policy: `programmatic_forced=1`, `selective_ai_auto=0`
  - score `-277.0`
- `pass3_note_2400`:
  - emitted `0`, no_emit `107`, no_advice `13`
  - score `-293.5`

Decision:
- Keep winner config:
  - `force_programmatic_synth=true`
  - `selective_ai_synth_enabled=true`
  - `selective_ai_min_authority=warning`
  - `selective_ai_min_remaining_ms=1800`
- Winner applied to `%USERPROFILE%\\.spark\\tuneables.json`.
- Tuneables backup for rollback:
  - `%USERPROFILE%\\.spark\\backups\\tuneables.json.selective_loop_20260216_144611.bak`

### Step 3: Prompt Sweep Coverage (#1, #3, #4, #5, #7)

Sweep artifact:
- `docs/reports/2026-02-16_prompt_sweep_1_3_4_5_7.md`

Key result:
- Prompt-sweep completed with explicit keep/needs_more_data decisions.
- Remaining blocker remains live-volume scarcity for non-benchmark selective-AI validation.

## Prompt #8 Output (2026-02-16, Autonomous)

Docs-to-implementation mapping completed in this cycle:
- Implementation files:
  - `lib/advisory_engine.py`
  - `scripts/advisory_controlled_delta.py`
  - `scripts/run_advisory_selective_ai_tune_loop.py`
- Validation files:
  - `tests/test_advisory_dual_path_router.py`
  - `tests/test_advisory_gate_suppression.py`
  - `tests/test_advisor_tool_specific_matching.py`
- Produced artifacts:
  - `docs/reports/20260216_145005_selective_ai_tune_loop_result.json`
  - `docs/reports/20260216_145005_selective_ai_tune_loop_report.md`

Decision:
- Keep implementation and telemetry upgrades.

## Tool Error Forensics - WebFetch (Prompt #9, 2026-02-16)

Scope:
- WebFetch rows from winner pass trace family:
  - `trace_id startswith delta-selective_loop_pass1_warning_1800-`

Observed:
- WebFetch rows: `3`
- Events: `no_emit=1`, `no_advice=2`
- Error codes: `AE_GATE_SUPPRESSED=1`, `AE_NO_ADVICE=2`
- Suppressed WebFetch row now carries explicit reason:
  - `gate_reason=\"phase=exploration, score=0.30, authority=silent, agree=1 (cognitive)\"`

Interpretation:
- Current WebFetch misses in this controlled pass are not transport/tool exceptions.
- They split between no-hit retrieval (`AE_NO_ADVICE`) and low-authority policy suppression (`AE_GATE_SUPPRESSED`).

Decision:
- Keep current WebFetch suppression hardening.
- Use `gate_reason` telemetry to separate retrieval misses from policy suppressions in future WebFetch forensics.

## Continuation Loop - Live Probe Follow-Up (2026-02-16)

Follow-up report:
- `docs/reports/2026-02-16_live_probe_followup.md`

What was executed:
1. Non-benchmark probe loop (80 rounds/pass) across three selective-AI candidates.
2. Improved probe loop (40 rounds/pass) with relaxed gate-threshold candidates.
3. Dedupe-off isolation probe to verify selective-AI activation and latency behavior.

Key outcomes:
- Non-benchmark probe rows were generated successfully.
- Selective-AI remained inactive in regular live-probe loops (`selective_hits=0`) despite threshold experiments.
- Dedupe-off isolation confirmed selective-AI can trigger (`selective_ai_auto=3`) but with unacceptable latency tail:
  - `p95_ms=12069.4`, `p90_ms=10853.2`

Runtime decision:
- Keep conservative hot-path profile (restored after probe exploration):
  - `force_programmatic_synth=true`
  - `selective_ai_synth_enabled=true`
  - `selective_ai_min_authority=warning`
  - `selective_ai_min_remaining_ms=1800`
  - `advisory_gate.note_threshold=0.5`
  - `advisory_gate.whisper_threshold=0.35`

Rollback safety:
- `%USERPROFILE%\\.spark\\backups\\tuneables.json.post_liveprobe_revert_20260216_191624.bak`

## Continuation Loop - Live Probe Hardening Pass (2026-02-16)

What was improved:
1. `scripts/run_advisory_selective_ai_live_probe_loop.py`
  - added per-candidate `synthesizer.ai_timeout_s`
  - added dedupe reset between passes (fair candidate comparison)
  - added viability-gated winner selection and conservative fallback reason
2. `lib/advisory_engine.py`
  - added selective eligibility diagnostics in emitted/synth-empty rows:
    - `selective_ai_eligible`
    - `remaining_ms_before_synth`
    - `emitted_authorities`
3. `scripts/advisory_controlled_delta.py`
  - added summary fields:
    - `engine.selective_ai_eligibility`
    - `engine.emitted_authority_counts`

New loop artifacts:
- `docs/reports/20260216_152532_selective_ai_live_probe_loop_result.json`
- `docs/reports/20260216_152532_selective_ai_live_probe_loop_report.md`

Focused evidence artifacts:
- `docs/reports/20260216_152700_liveprobe_focus_note1400_gate035_t09.json`
- `docs/reports/20260216_152830_liveprobe_focus_whisper1200_gate035_t09.json`
- `docs/reports/20260216_153300_liveprobe_focus_warning1800_gate035_t09.json`

Key outcomes:
- Whisper-authority selective policy activated selective-AI (`eligible=38`, `selective_ai_auto=1`) but failed latency budget (`p95~4520.9ms`).
- Warning-authority policy with relaxed gate thresholds kept selective path guarded (`not_eligible=37`) and bounded latency (`p95~606.4ms`) while reducing gate suppression vs strict `note_threshold=0.5`.

Final runtime decision (safe-improved):
- `force_programmatic_synth=true`
- `selective_ai_synth_enabled=true`
- `selective_ai_min_authority=warning`
- `selective_ai_min_remaining_ms=1800`
- `advisory_gate.note_threshold=0.35`
- `advisory_gate.whisper_threshold=0.25`
- `synthesizer.ai_timeout_s=0.9`
- rollback-safe backup:
  - `%USERPROFILE%\\.spark\\backups\\tuneables.json.safe_improved_liveprobe_20260216_193719.bak`
