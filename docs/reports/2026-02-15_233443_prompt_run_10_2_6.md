# Prompt Run: #10 Weekly Review, #2 Memory Retrieval Audit, #6 Tuneables Experiment Plan

Generated: 2026-02-15

This is a single running log for using the prompt library:
- `prompts/SPARK_INTELLIGENCE_PROMPT_LIBRARY.md`

Sources used (evidence):
- `docs/reports/2026-02-15_124723_advisory_self_review.md`
- `docs/reports/2026-02-14_retrieval_routing_abcd_live_v1.md`
- `docs/reports/2026-02-13_advisory_repeat_abcd_controlled_delta_v1.md`
- `docs/memory-retrieval-status.md`
- `%USERPROFILE%\\.spark\\tuneables.json`
- `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`
- `%USERPROFILE%\\.spark\\advisory_engine.jsonl`
- `%USERPROFILE%\\.spark\\advisory_emit.jsonl`
- `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl`
- `%USERPROFILE%\\.spark\\sync_stats.json`
- `%USERPROFILE%\\.spark\\pipeline_state.json`

---

## Prompt #10: "Compound the Learnings" Weekly Review

Window (chosen): 2026-02-09 to 2026-02-15 (inclusive)

### What Improved (Evidence-Backed)
- Retrieval routing A/B/C/D executed and a winner was chosen, with Arm C (`lexical_weight=0.28`) applied live to `~/.spark/tuneables.json -> retrieval.overrides.*`. Evidence: `docs/reports/2026-02-14_retrieval_routing_abcd_live_v1.md`, `%USERPROFILE%\\.spark\\tuneables.json`.
- Advisory repeat A/B/C/D suggests repeat-noise can be reduced: `feedback_top_share` is 57.14% in A/B, 36.36% in C, 25.00% in D. Evidence: `docs/reports/2026-02-13_advisory_repeat_abcd_controlled_delta_v1.md`.
- Memory retrieval has a concrete quality/latency benchmark surface and explicit diagnostics + error taxonomy contract. Evidence: `docs/memory-retrieval-status.md`.

### What Regressed (Evidence-Backed)
- Advisory self-review (12h window) shows advisory trace coverage at 0/11 (0%), and engine trace coverage at 3/13 (23.08%), which blocks attribution. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
- Advisory noise is highly concentrated in that same 12h window: "Top repeated advisories account for ~92.0% of all advice items". Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
- Current pipeline telemetry shows consecutive empty cycles (12) which may be normal if idle, but indicates the learning pipeline is not processing any queued events right now. Evidence: `%USERPROFILE%\\.spark\\pipeline_state.json`, `%USERPROFILE%\\.spark\\pipeline_metrics.json`.

### Top Learnings To Keep (Evidence-Backed)
- Constraint: in exactly one state at all times. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.
- Always read a file before Edit to verify current content. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.
- Error taxonomy split (`auth|timeout|policy|transport|unknown`) for retrieval failures (prevents false "auth blocked" narratives). Evidence: `docs/memory-retrieval-status.md`.

### Top Learnings To Kill/Suppress (Evidence-Backed)
- Suppress long repeated "When using Bash..." advisory family (high repetition in window, low actionability for PowerShell-first operation). Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
- Suppress long repeated "lets push gitthub..." advisory family (high repetition, not tied to current acceptance). Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl` (recent window counts below).

### Next Week: 3 Bets (Measurable + Rollback)
1. Improve advisory trace discipline end-to-end. Metric: advisory trace coverage from 0% toward >=60%. Rollback: revert strict trace requirements if strict effectiveness drops. Evidence baseline: `docs/reports/2026-02-15_124723_advisory_self_review.md`.
2. Reduce repeat-noise concentration. Metric: top-repeat share from ~92% toward <=40%. Rollback: if critical misses increase. Evidence: `docs/reports/2026-02-15_124723_advisory_self_review.md`, `docs/reports/2026-02-13_advisory_repeat_abcd_controlled_delta_v1.md`.
3. Ship retrieval diagnostics + error-kind classification coverage. Metric: 100% non-empty `error_kind` for failures. Rollback: disable new diagnostics endpoints if destabilizing. Evidence: `docs/memory-retrieval-status.md`.

---

## Prompt #2: Memory Retrieval Audit (Wins/Misses With Evidence)

Window (available evidence): 2026-02-15 14:26:43Z to 2026-02-15 18:24:29Z for retrieval routing (`~/.spark/advisor/retrieval_router.jsonl`).

### Evidence Summary
- Routing events analyzed: 834. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Advisory engine event slice available: 2026-02-15 18:20:03Z to 2026-02-15 18:24:58Z (500 events). Evidence: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.
- Advisory emit history available: 2026-02-13 23:05:31Z to 2026-02-15 18:24:38Z (500 emits). Evidence: `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.
- Sync status: multiple optional adapters are disabled (CLAUDE.md, Cursor, Windsurf, Clawdbot); core adapters `exports` and `openclaw` report success. Evidence: `%USERPROFILE%\\.spark\\sync_stats.json`.

### Retrieval Wins
- Some calls do retrieve non-empty semantic results under the `balanced_spend` profile (10 events) with non-zero `primary_count` (4-5) and non-zero `primary_top_score` (~0.19-0.24). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` (profile_name=`balanced_spend` rows).

### Retrieval Misses / Failure Modes
- The retrieval router is overwhelmingly in `local_free` profile: 824/834 events (98.8%). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Route outcomes are dominated by `empty`: 711/834 (85.3%). Escalation happens 85/834 (10.2%). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Primary retrieval quality is very low: only 40/834 events have `primary_count > 0` (4.8%), and 0/834 have `primary_top_score > 0.5`. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Top miss reasons are consistently logged:
  - `empty_primary`: 794
  - `agentic_rate_cap`: 739
  - `weak_primary_score`: 534
  - `weak_primary_count`: 525
  Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- The tuned routing overrides (Arm C values) are not being applied to most traffic because `local_free` events that include routing parameters show baseline-like values (0.25/0.15/0.03/0.90/0.1) while `balanced_spend` events show the tuned values (0.28/0.18/0.05/0.92/0.2). Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`, `%USERPROFILE%\\.spark\\tuneables.json`, `docs/reports/2026-02-14_retrieval_routing_abcd_live_v1.md`.

### Advisory Delivery Misses (Policy Suppression)
- In the `advisory_engine.jsonl` slice, `no_emit` happens 200/500 times, and all 200 are `error_kind=policy` with `error_code=AE_GATE_SUPPRESSED`. Evidence: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.
- This indicates advice candidates exist but are being blocked at the gate for this window; if this is intended, it should be reflected in trace-linked success criteria, otherwise it hides issues behind "no advice". Evidence: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`, `docs/reports/2026-02-15_124723_advisory_self_review.md`.

### Noise Snapshot (Recent 72h, Feedback Requests)
- Recent (last ~72h) feedback requests show high repetition of a small set of advice:
  - "Constraint: in **exactly one state** at all times" (187)
  - "Always Read a file before Edit to verify current content" (93)
  - "[Caution] I struggle with WebFetch fails with other tasks" (78)
  Evidence: `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl` (filtered by `created_at`).

### Tuning Actions (Ordered, No New Features)
1. Fix profile selection so the tuned `retrieval.overrides.*` are applied to the majority of tool calls (or ensure `local_free` also honors the overrides). Success metric: `route=empty` share drops materially and `primary_count>0` increases. Evidence motivating: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
2. Reduce the dominance of `agentic_rate_cap` when `empty_primary` is true (either by raising `agentic_rate_limit` for `local_free`, or by allowing escalation on repeated empties). Success metric: fewer `agentic_rate_cap` blocks and higher `returned_count` on escalations. Evidence motivating: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
3. Reconcile advisory gate suppression with desired behavior: if `AE_GATE_SUPPRESSED` blocks 200/250 decision points, the system needs an explicit target for that ratio. Success metric: lower policy-suppressed share or clearer trace-linked justification. Evidence motivating: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.

---

## Prompt #6: Tuneables Experiment Plan (A/B/C/D With Rollback)

### Proposed Change (High-Leverage)
Make retrieval policy consistent and more permissive so primary retrieval is non-empty more often (reducing `route=empty` and `empty_primary` dominance), while controlling cost/latency and repeat noise.

Why this is the candidate:
- In the analyzed routing window, `route=empty` is 711/834 (85.3%) and `empty_primary` is logged 794 times. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- `agentic_rate_cap` is logged 739 times, meaning even when escalation is indicated, it is frequently blocked. Evidence: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Semantic retrieval frequently yields no final results even when embeddings are available (1501/2246 empty final_results). Evidence: `%USERPROFILE%\\.spark\\logs\\semantic_retrieval.jsonl`.

### Experiment Design

Variants (A/B/C/D):
1. **A (Baseline)**: current runtime behavior (no changes).
2. **B (Consistency)**: ensure all Spark processes load the same retrieval policy:
   - Set/confirm `retrieval.level="2"` in `%USERPROFILE%\\.spark\\tuneables.json`.
   - Restart Spark services that host the advisor/advisory engine so `SparkAdvisor.retrieval_policy` reloads (it is loaded at initialization). Evidence: `lib/advisor.py` (loads policy in `SparkAdvisor.__init__`).
3. **C (Permissive Primary)**: B + relax matching thresholds used by the advisor filter to reduce empty finals:
   - `retrieval.overrides.semantic_context_min`: 0.18 -> 0.12
   - `retrieval.overrides.semantic_lexical_min`: 0.05 -> 0.02
4. **D (Reduce Rate-Cap Blocking)**: C + raise escalation allowance:
   - `retrieval.overrides.agentic_rate_limit`: 0.20 -> 0.35
   - keep `retrieval.overrides.agentic_rate_window` at 80 (unchanged)

Primary metrics:
- Retrieval router:
  - `route=empty` share
  - `primary_count>0` rate
  - `agentic_rate_cap` frequency
  - `returned_count` mean/p95 (for `semantic|semantic-agentic`)
  Evidence source: `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
- Semantic retrieval:
  - `final_results_empty` rate
  Evidence source: `%USERPROFILE%\\.spark\\logs\\semantic_retrieval.jsonl`.
- Advisory delivery:
  - `AE_GATE_SUPPRESSED` share (no-emit reason histogram)
  Evidence source: `%USERPROFILE%\\.spark\\advisory_engine.jsonl`.
- Repeat-noise:
  - top 1 and top 3 advice share
  Evidence source: `%USERPROFILE%\\.spark\\advice_feedback_requests.jsonl`, `%USERPROFILE%\\.spark\\advisory_emit.jsonl`.

Secondary metrics:
- Latency: `route_elapsed_ms` (router) and `elapsed_ms` (advisory engine) p95.
- Safety: `critical_miss_rate`/realism objective if you run contract benches. Evidence surface: `docs/ADVISORY_BENCHMARK_SYSTEM.md`.

Sample size / timebox:
- Minimum: 10 minutes per variant under real work, or run a standardized synthetic workload.
- Recommended synthetic runner: `python scripts/advisory_controlled_delta.py --rounds 160 --force-live --out docs/reports/<variant>_controlled_delta.json`
  - Note: by default this script resets `~/.spark/advice_feedback_state.json`; pass `--no-reset-feedback-state` if you want to preserve it.

Stop conditions:
- If p95 advisory latency exceeds 3500ms (current `advisory_engine.max_ms`) or spikes materially.
- If repeat-noise worsens (top-1 share rises) without a matching lift in retrieval non-empties.
- If `semantic_retrieval.jsonl` starts showing increased `final_results` but advice quality regresses (more irrelevant emits).

Rollback criteria:
- If `route=empty` does not improve by at least 20% relative (e.g., 85% -> <=68%) after C or D.
- If repeat-noise gets worse (top-3 share increases) without higher strict effectiveness.
- If engine suppression dominates more than baseline (higher `AE_GATE_SUPPRESSED` share) and trace coverage remains low.

Rollback mechanism:
- Restore `%USERPROFILE%\\.spark\\tuneables.json` from a known-good backup (example present: `%USERPROFILE%\\.spark\\tuneables.json.prune_advisor_retrieval_policy_backup_20260214_034633`) or revert the specific keys.
- Restart services to apply rollback (policy is loaded at advisor init).

### Execution Steps (Minimal)
1. Snapshot current tuneables + logs:
   - Copy `%USERPROFILE%\\.spark\\tuneables.json` to a timestamped backup.
   - Record baseline router stats from `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl`.
2. Apply Variant B (consistency) and restart Spark services.
3. Run the same workload for each variant (real work window or `scripts/advisory_controlled_delta.py`) and record:
   - router stats
   - semantic final_results_empty rate
   - advisory no-emit histogram (error_code)
4. Choose winner using primary metrics; only keep the smallest change-set that achieves the lift.

### Variant B (Executed) Findings (2026-02-15)

Artifacts created:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantB_20260215_234717.bak`
- Controlled delta (pre): `docs/reports/2026-02-15_233443_variantB_pre.json`
- Controlled delta (post, before BOM fix): `docs/reports/2026-02-15_233443_variantB_post.json`
- Controlled delta (post, after BOM fix): `docs/reports/2026-02-15_233443_variantB_post_bomfix.json`

Root cause discovered (blocking all tuneables usage):
- `%USERPROFILE%\\.spark\\tuneables.json` contained a UTF-8 BOM.
- Multiple loaders use `json.loads(tuneables.read_text(encoding="utf-8"))`; Python raises `JSONDecodeError: Unexpected UTF-8 BOM`.
- The advisor retrieval policy loader silently swallowed the exception and fell back to defaults (Level 1 / `local_free`), explaining why routing overrides were not applied.

Fix applied:
- Rewrote `%USERPROFILE%\\.spark\\tuneables.json` by reading with `utf-8-sig` and writing without BOM (UTF-8).
- Restarted Spark services (`python -m spark.cli down` then `python -m spark.cli up`) so long-lived processes reload tuneables.
- Hardened runtime loaders to accept UTF-8 with BOM by switching tuneables reads to `encoding="utf-8-sig"` (prevents recurrence even if an editor writes BOM).

Measured effect (same synthetic workload: `scripts/advisory_controlled_delta.py --rounds 120 --force-live --no-reset-feedback-state`):
- **Pre (2026-02-15 19:47:31Z)** router window (120 rows):
  - Profile: 120/120 `local_free` (level 1)
  - Routes: `empty` 105, `semantic-agentic` 12, `semantic` 3
  - `escalated_true`: 12/120
- **Post after BOM fix (2026-02-15 19:57:01Z)** router window (120 rows):
  - Profile: 120/120 `balanced_spend` (level 2)
  - Routes: `empty` 92, `semantic-agentic` 24, `semantic` 4
  - `escalated_true`: 24/120
- Advisory engine p95 latency increased (expected with more escalation): p95 ~420ms (pre) -> ~540ms (post after BOM fix). Evidence: JSON artifacts above.

### Variant C (Executed) Findings (2026-02-15)

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.semantic_context_min`: 0.18 -> 0.12
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.semantic_lexical_min`: 0.05 -> 0.02

Artifacts:
- Controlled delta: `docs/reports/2026-02-15_233443_variantC.json`

Measured effect vs Variant B (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows):
  - **B** routes: `empty` 92, `semantic-agentic` 24, `semantic` 4 (empty share 76.7%)
  - **C** routes: `semantic` 120, `empty` 0 (empty share 0.0%)
  - **B** `primary_count>0`: 4/120
  - **C** `primary_count>0`: 120/120
- Router detail in C:
  - `returned_count` mean: 1.925 (min 1, max 4)
  - `primary_top_score` mean: 0.0139 (min 0.0, max 0.0617)  (note: still extremely low)
- Advisory engine p95 latency:
  - **B** p95 ~540ms
  - **C** p95 ~759ms

Decision:
- Keep Variant C changes (massive reduction in `route=empty`, within advisory time budgets).

### Variant C+ (Executed) Findings (2026-02-15)

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.escalate_on_weak_primary`: false -> true

Artifacts:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantCplus_20260216_005907.bak`
- Controlled delta: `docs/reports/2026-02-16_010226_variantC_plus.json`

Measured effect vs Variant C (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows; first 120 rows in `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` with `ts >= 2026-02-15T21:02:27Z`):
  - Routes: `semantic` 95, `semantic-agentic` 25, `empty` 0
  - `escalated_true`: 25/120
  - `primary_count>0`: 120/120
  - `returned_count` mean: 2.108 (min 1, max 7)
  - `primary_top_score` mean: 0.0144 (min 0.0, max 0.0680)  (note: still extremely low)
  - Top reasons: `weak_primary_score` 120, `agentic_rate_cap` 95
- Advisory engine p95 latency (from controlled delta JSON): p95 741.4ms (n=8 emitted)

Interpretation:
- `escalate_on_weak_primary=true` is taking effect (25/120 routes went `semantic-agentic`), but `agentic_rate_cap` is now the dominant limiter (95/120 rows log it).

### Variant D (Executed) Findings (2026-02-15)

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.agentic_rate_limit`: 0.2 -> 0.35

Artifacts:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantD_20260216_015256.bak`
- Controlled delta: `docs/reports/2026-02-16_015504_variantD_agentic_rate_035.json`

Measured effect vs Variant C+ (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows; first 120 rows in `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` with `ts >= 2026-02-15T21:55:05Z`):
  - Routes: `semantic` 78, `semantic-agentic` 42, `empty` 0
  - `escalated_true`: 42/120
  - `primary_count>0`: 120/120
  - `returned_count` mean: 2.733 (min 1, max 6)
  - `primary_top_score` mean: 0.0139 (min 0.0, max 0.0617)  (note: still extremely low)
  - Top reasons: `weak_primary_score` 120, `agentic_rate_cap` 78
- Advisory engine p95 latency (from controlled delta JSON): p95 389.2ms (n=7 emitted)

Decision:
- Keep `agentic_rate_limit=0.35` (material reduction in `agentic_rate_cap` frequency and higher `returned_count`), while tracking advisory emit rate and any quality regressions.

### Variant E (Executed) Findings (2026-02-15)

Goal:
- Reduce unnecessary `weak_primary_score` triggers by calibrating the score threshold to the observed score scale (scores peak around ~0.06 in this environment).

Change applied (tuneables):
- `%USERPROFILE%\\.spark\\tuneables.json` -> `retrieval.overrides.min_top_score_no_escalation`: 0.72 -> 0.02

Artifacts:
- Tuneables backup: `%USERPROFILE%\\.spark\\backups\\tuneables.json.variantE_20260216_024440.bak`
- Controlled delta: `docs/reports/2026-02-16_024647_variantE_minTopScore_002.json`

Measured effect vs Variant D (same workload: 120 rounds, `--force-live`, `--no-reset-feedback-state`):
- Router window (120 rows; first 120 rows in `%USERPROFILE%\\.spark\\advisor\\retrieval_router.jsonl` with `ts >= 2026-02-15T22:46:47Z`):
  - Routes: `semantic` 80, `semantic-agentic` 40, `empty` 0
  - `escalated_true`: 40/120
  - `primary_count>0`: 120/120
  - `returned_count` mean: 2.783 (min 1, max 7)
  - `primary_top_score` mean: 0.01387 (min 0.0, max 0.0617)
  - Top reasons: `weak_primary_score` 82 (down from 120), `agentic_rate_cap` 42 (down from 78)
- Advisory engine p95 latency (from controlled delta JSON): p95 269.9ms (n=2 emitted)

Decision:
- Keep `min_top_score_no_escalation=0.02` for now (large drop in `weak_primary_score` and `agentic_rate_cap`), but the controlled-delta run emitted very little advice (2 emits) so this needs a longer soak window to be confident.
