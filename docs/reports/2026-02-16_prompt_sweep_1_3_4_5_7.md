# Prompt Sweep: #1, #3, #4, #5, #7 (2026-02-16)

Generated: 2026-02-16 (UTC)  
Context: autonomous run while operator away; benchmark-first loop with explicit keep/rollback notes.

## Prompt #1 - Stuck-State Triage

Stuck state identified:
- Selective-AI tuning could not be validated on real non-benchmark traffic.

Evidence:
- Last 24h advisory-engine rows excluding `advisory-bench-*` and `delta-*`: `0`.
- Last 6h equivalent window: `0`.

Action taken:
- Shifted optimization loop to controlled benchmark traffic with full telemetry and rollback.

Decision:
- `keep`: benchmark loop for deterministic tuning.
- `needs_more_data`: live selective-AI trigger conclusions.

## Prompt #3 - Observation -> Schema-First Chip

Observation:
- Suppression and synthesis policy were previously under-instrumented for fast diagnosis.

Schema-first implementation shipped:
- `gate_reason` (primary suppression reason)
- `suppressed_count`
- `suppressed_reasons` (reason histogram)
- `synth_policy` on emit/synth events

Evidence:
- `lib/advisory_engine.py`
- `tests/test_advisory_dual_path_router.py`
- Runtime rows now include the new fields for `AE_GATE_SUPPRESSED`.

Decision:
- `keep`: telemetry schema changes.

## Prompt #4 - Meta-Ralph Quality Gate

Fresh self-review snapshot:
- Command: `python scripts/advisory_self_review.py --window-hours 6 --json`
- Strict action rate: `0.5238`
- Strict effectiveness rate: `0.6364`
- Trace mismatch count: `5`

Interpretation:
- Attribution quality is active but still mixed; strict effectiveness is not yet strong enough to loosen gate strictness.

Decision:
- `keep`: strict attribution posture.
- `next`: re-check after additional non-benchmark volume.

## Prompt #5 - DEPTH Session Designer

Session design (ready for next operator pass):
1. Session A (30-40 min): suppression forensics
- Goal: reduce repeated silent-policy suppressions without over-emitting.
- Metric: lower `AE_GATE_SUPPRESSED` share in controlled pass with stable latency.

2. Session B (30-40 min): synthesis-path verification
- Goal: produce non-zero selective AI hits under a safe budget slice.
- Metric: `emitted_synth_policy_counts.selective_ai_auto > 0` with `p95 < 1500ms`.

3. Session C (30-40 min): outcome-quality tightening
- Goal: improve strict effectiveness from current ~0.64.
- Metric: strict effectiveness >= 0.75 over a comparable window.

Decision:
- `keep`: this 3-session sequence as the next focused training/tuning block.

## Prompt #7 - Cut List

Cuts applied in this cycle:
- Cut candidate configs that degraded score (`note` authority variants).
- Cut assumptions without telemetry (no more selective-AI claims without `synth_policy` evidence).

Cuts deferred:
- No gate-threshold surgery on live runtime until non-benchmark traffic appears.

Decision:
- `keep`: winner config (`warning`, `1800ms`) and remove failing variants from active experimentation.

## Sweep Artifacts

- `docs/reports/20260216_145005_selective_ai_tune_loop_result.json`
- `docs/reports/20260216_145005_selective_ai_tune_loop_report.md`
- `docs/reports/20260216_144611_pass1_warning_1800_selective_loop.json`
- `docs/reports/20260216_144733_pass2_note_1800_selective_loop.json`
- `docs/reports/20260216_144853_pass3_note_2400_selective_loop.json`
